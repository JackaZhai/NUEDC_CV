#!/usr/bin/env python3
"""
VOCæ•°æ®é›†è½¬YOLOæ ¼å¼è„šæœ¬
ä½¿ç”¨æ–¹æ³•: python utils/voc_to_yolo.py --voc_dir /path/to/voc --classes person car bike
"""

import argparse
import os
import sys
from pathlib import Path
import shutil
import xml.etree.ElementTree as ET
import random
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
ROOT = Path(__file__).resolve().parent.parent
sys.path.append(str(ROOT))

def convert_bbox(size, box):
    """
    è½¬æ¢è¾¹ç•Œæ¡†æ ¼å¼ï¼šä»VOCçš„ç»å¯¹åæ ‡è½¬æ¢ä¸ºYOLOçš„ç›¸å¯¹åæ ‡
    
    Args:
        size: (width, height) å›¾åƒå°ºå¯¸
        box: (xmin, ymin, xmax, ymax) VOCæ ¼å¼è¾¹ç•Œæ¡†
    
    Returns:
        (x, y, w, h) YOLOæ ¼å¼è¾¹ç•Œæ¡†ï¼ˆç›¸å¯¹åæ ‡ï¼‰
    """
    dw = 1.0 / size[0]  # å®½åº¦å½’ä¸€åŒ–å› å­
    dh = 1.0 / size[1]  # é«˜åº¦å½’ä¸€åŒ–å› å­
    x = (box[0] + box[2]) / 2.0  # ä¸­å¿ƒç‚¹x
    y = (box[1] + box[3]) / 2.0  # ä¸­å¿ƒç‚¹y
    w = box[2] - box[0]  # å®½åº¦
    h = box[3] - box[1]  # é«˜åº¦
    
    # å½’ä¸€åŒ–åˆ°[0,1]
    x = x * dw
    w = w * dw
    y = y * dh
    h = h * dh
    
    return (x, y, w, h)

def parse_xml_annotation(xml_file, class_names):
    """
    è§£æXMLæ ‡æ³¨æ–‡ä»¶
    
    Args:
        xml_file: XMLæ–‡ä»¶è·¯å¾„
        class_names: ç±»åˆ«åç§°åˆ—è¡¨
    
    Returns:
        annotations: æ ‡æ³¨åˆ—è¡¨
        image_info: å›¾åƒä¿¡æ¯ (filename, width, height)
    """
    tree = ET.parse(xml_file)
    root = tree.getroot()
    
    # è·å–å›¾åƒä¿¡æ¯
    filename = root.find('filename').text
    size = root.find('size')
    width = int(size.find('width').text)
    height = int(size.find('height').text)
    
    annotations = []
    
    # è§£ææ‰€æœ‰ç›®æ ‡
    for obj in root.findall('object'):
        class_name = obj.find('name').text
        
        # è·³è¿‡ä¸åœ¨æŒ‡å®šç±»åˆ«ä¸­çš„ç›®æ ‡
        if class_name not in class_names:
            continue
        
        class_id = class_names.index(class_name)
        
        # è·å–è¾¹ç•Œæ¡†
        bbox = obj.find('bndbox')
        xmin = float(bbox.find('xmin').text)
        ymin = float(bbox.find('ymin').text)
        xmax = float(bbox.find('xmax').text)
        ymax = float(bbox.find('ymax').text)
        
        # è½¬æ¢ä¸ºYOLOæ ¼å¼
        bbox_yolo = convert_bbox((width, height), (xmin, ymin, xmax, ymax))
        
        annotations.append({
            'class_id': class_id,
            'bbox': bbox_yolo
        })
    
    return annotations, (filename, width, height)

def convert_voc_to_yolo(voc_dir, output_dir, class_names, train_ratio=0.8):
    """
    å°†VOCæ ¼å¼æ•°æ®é›†è½¬æ¢ä¸ºYOLOæ ¼å¼
    
    Args:
        voc_dir: VOCæ•°æ®é›†æ ¹ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        class_names: ç±»åˆ«åç§°åˆ—è¡¨
        train_ratio: è®­ç»ƒé›†æ¯”ä¾‹
    """
    voc_path = Path(voc_dir)
    output_path = Path(output_dir)
    
    # æ£€æŸ¥VOCç›®å½•ç»“æ„
    annotations_dir = voc_path / "Annotations"
    
    # å°è¯•å¤šç§å¯èƒ½çš„å›¾åƒç›®å½•åç§°
    possible_image_dirs = ["Images", "JPEGImages", "images", "jpegimages"]
    images_dir = None
    
    for dir_name in possible_image_dirs:
        potential_dir = voc_path / dir_name
        if potential_dir.exists():
            images_dir = potential_dir
            print(f"âœ… æ‰¾åˆ°å›¾åƒç›®å½•: {images_dir}")
            break
    
    if not annotations_dir.exists():
        print(f"âŒ é”™è¯¯: {annotations_dir} ä¸å­˜åœ¨")
        return False
    
    if images_dir is None:
        print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ°å›¾åƒç›®å½•ï¼Œæ£€æŸ¥äº†ä»¥ä¸‹ä½ç½®:")
        for dir_name in possible_image_dirs:
            print(f"   - {voc_path / dir_name}")
        return False
    
    # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
    for split in ['train', 'val']:
        (output_path / 'images' / split).mkdir(parents=True, exist_ok=True)
        (output_path / 'labels' / split).mkdir(parents=True, exist_ok=True)
    
    # è·å–æ‰€æœ‰XMLæ–‡ä»¶
    xml_files = list(annotations_dir.glob("*.xml"))
    if not xml_files:
        print(f"é”™è¯¯: åœ¨ {annotations_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°XMLæ–‡ä»¶")
        return False
    
    print(f"æ‰¾åˆ° {len(xml_files)} ä¸ªæ ‡æ³¨æ–‡ä»¶")
    
    # éšæœºåˆ†å‰²è®­ç»ƒå’ŒéªŒè¯é›†
    random.shuffle(xml_files)
    split_idx = int(len(xml_files) * train_ratio)
    train_files = xml_files[:split_idx]
    val_files = xml_files[split_idx:]
    
    print(f"è®­ç»ƒé›†: {len(train_files)} ä¸ªæ–‡ä»¶")
    print(f"éªŒè¯é›†: {len(val_files)} ä¸ªæ–‡ä»¶")
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_converted = 0
    total_objects = 0
    missing_images = []
    
    def process_files(files, split):
        """å¤„ç†æ–‡ä»¶åˆ—è¡¨"""
        nonlocal total_converted, total_objects
        
        split_converted = 0
        split_objects = 0
        
        print(f"\nå¤„ç† {split} é›†...")
        
        for xml_file in tqdm(files, desc=f"è½¬æ¢{split}é›†"):
            try:
                # è§£æXMLæ ‡æ³¨
                annotations, (filename, width, height) = parse_xml_annotation(xml_file, class_names)
                
                # æ£€æŸ¥å¯¹åº”çš„å›¾åƒæ–‡ä»¶æ˜¯å¦å­˜åœ¨
                img_extensions = ['.jpg', '.jpeg', '.png', '.bmp']
                img_file = None
                
                for ext in img_extensions:
                    potential_img = images_dir / filename.replace('.jpg', ext).replace('.jpeg', ext).replace('.png', ext).replace('.bmp', ext)
                    if potential_img.exists():
                        img_file = potential_img
                        break
                
                if img_file is None:
                    # å°è¯•ä¸å¸¦æ‰©å±•åçš„æ–‡ä»¶å
                    base_name = Path(filename).stem
                    for ext in img_extensions:
                        potential_img = images_dir / f"{base_name}{ext}"
                        if potential_img.exists():
                            img_file = potential_img
                            break
                
                if img_file is None:
                    missing_images.append(filename)
                    continue
                
                # å¤åˆ¶å›¾åƒæ–‡ä»¶åˆ°è¾“å‡ºç›®å½•
                dst_img = output_path / 'images' / split / img_file.name
                shutil.copy2(str(img_file), str(dst_img))
                
                # åˆ›å»ºYOLOæ ¼å¼æ ‡ç­¾æ–‡ä»¶
                label_file = output_path / 'labels' / split / f"{xml_file.stem}.txt"
                
                with open(label_file, 'w') as f:
                    for ann in annotations:
                        bbox = ann['bbox']
                        f.write(f"{ann['class_id']} {bbox[0]:.6f} {bbox[1]:.6f} {bbox[2]:.6f} {bbox[3]:.6f}\n")
                
                split_converted += 1
                split_objects += len(annotations)
                
            except Exception as e:
                print(f"\nå¤„ç†æ–‡ä»¶ {xml_file} æ—¶å‡ºé”™: {e}")
                continue
        
        print(f"{split}é›†è½¬æ¢å®Œæˆ: {split_converted} ä¸ªæ–‡ä»¶, {split_objects} ä¸ªç›®æ ‡")
        return split_converted, split_objects
    
    # å¤„ç†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    train_converted, train_objects = process_files(train_files, 'train')
    val_converted, val_objects = process_files(val_files, 'val')
    
    total_converted = train_converted + val_converted
    total_objects = train_objects + val_objects
    
    # åˆ›å»ºæ•°æ®é›†é…ç½®æ–‡ä»¶
    dataset_config = f"""# ä»VOCè½¬æ¢çš„æ•°æ®é›†é…ç½®
# åŸå§‹VOCç›®å½•: {voc_dir}
# è½¬æ¢æ—¶é—´: {Path(__file__).stat().st_mtime}

# æ•°æ®è·¯å¾„
train: {output_path}/images/train
val: {output_path}/images/val

# ç±»åˆ«æ•°é‡
nc: {len(class_names)}

# ç±»åˆ«åç§°
names:
"""
    
    for i, class_name in enumerate(class_names):
        dataset_config += f"  {i}: '{class_name}'\n"
    
    config_file = output_path / 'dataset.yaml'
    with open(config_file, 'w', encoding='utf-8') as f:
        f.write(dataset_config)
    
    # æ‰“å°è½¬æ¢ç»Ÿè®¡
    print("\n" + "="*50)
    print("è½¬æ¢å®Œæˆç»Ÿè®¡:")
    print(f"æ€»æ–‡ä»¶æ•°: {len(xml_files)}")
    print(f"æˆåŠŸè½¬æ¢: {total_converted}")
    print(f"æ€»ç›®æ ‡æ•°: {total_objects}")
    print(f"ç±»åˆ«æ•°é‡: {len(class_names)}")
    print(f"ç±»åˆ«åˆ—è¡¨: {class_names}")
    
    if missing_images:
        print(f"\nç¼ºå¤±å›¾åƒæ–‡ä»¶: {len(missing_images)}")
        if len(missing_images) <= 10:
            for img in missing_images:
                print(f"  - {img}")
        else:
            for img in missing_images[:10]:
                print(f"  - {img}")
            print(f"  ... è¿˜æœ‰ {len(missing_images)-10} ä¸ª")
    
    print(f"\nè¾“å‡ºç›®å½•: {output_path}")
    print(f"é…ç½®æ–‡ä»¶: {config_file}")
    print("="*50)
    
    return True

def scan_voc_classes(voc_dir):
    """
    æ‰«æVOCæ•°æ®é›†ä¸­çš„æ‰€æœ‰ç±»åˆ«
    
    Args:
        voc_dir: VOCæ•°æ®é›†ç›®å½•
    
    Returns:
        set: ç±»åˆ«åç§°é›†åˆ
    """
    annotations_dir = Path(voc_dir) / "Annotations"
    
    if not annotations_dir.exists():
        print(f"é”™è¯¯: {annotations_dir} ä¸å­˜åœ¨")
        return set()
    
    classes = set()
    xml_files = list(annotations_dir.glob("*.xml"))
    
    print(f"æ‰«æ {len(xml_files)} ä¸ªæ ‡æ³¨æ–‡ä»¶...")
    
    for xml_file in tqdm(xml_files, desc="æ‰«æç±»åˆ«"):
        try:
            tree = ET.parse(xml_file)
            root = tree.getroot()
            
            for obj in root.findall('object'):
                class_name = obj.find('name').text
                if class_name:
                    classes.add(class_name)
        except Exception as e:
            print(f"è§£ææ–‡ä»¶ {xml_file} æ—¶å‡ºé”™: {e}")
            continue
    
    return classes

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='VOCæ•°æ®é›†è½¬YOLOæ ¼å¼å·¥å…·')
    parser.add_argument('voc_dir', nargs='?', help='VOCæ•°æ®é›†ç›®å½•è·¯å¾„ (å¯ç›´æ¥ç²˜è´´è·¯å¾„)')
    parser.add_argument('--output', '-o', type=str, default='data', help='è¾“å‡ºç›®å½• (é»˜è®¤: data)')
    parser.add_argument('--classes', '-c', nargs='+', help='ç±»åˆ«åç§°åˆ—è¡¨ï¼Œä¾‹å¦‚: person car bike')
    parser.add_argument('--train_ratio', '-r', type=float, default=0.8, help='è®­ç»ƒé›†æ¯”ä¾‹ (é»˜è®¤: 0.8)')
    parser.add_argument('--scan', '-s', action='store_true', help='æ‰«ææ•°æ®é›†ä¸­çš„æ‰€æœ‰ç±»åˆ«')
    parser.add_argument('--auto', '-a', action='store_true', help='è‡ªåŠ¨æ£€æµ‹ç±»åˆ«å¹¶è½¬æ¢')
    
    args = parser.parse_args()
    
    # å¦‚æœæ²¡æœ‰æä¾›VOCç›®å½•ï¼Œæç¤ºç”¨æˆ·è¾“å…¥
    if not args.voc_dir:
        print("=== VOCåˆ°YOLOæ•°æ®é›†è½¬æ¢å·¥å…· ===")
        print()
        voc_dir = input("è¯·è¾“å…¥æˆ–ç²˜è´´VOCæ•°æ®é›†ç›®å½•è·¯å¾„: ").strip()
        if not voc_dir:
            print("âŒ æœªè¾“å…¥ç›®å½•è·¯å¾„")
            return 1
        # ç§»é™¤å¯èƒ½çš„å¼•å·
        voc_dir = voc_dir.strip('"').strip("'")
    else:
        voc_dir = args.voc_dir.strip('"').strip("'")
    
    # æ£€æŸ¥VOCç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(voc_dir):
        print(f"âŒ é”™è¯¯: VOCç›®å½• {voc_dir} ä¸å­˜åœ¨")
        return 1
    
    print(f"ğŸ“ VOCæ•°æ®é›†ç›®å½•: {voc_dir}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output}")
    
    # å¦‚æœéœ€è¦æ‰«æç±»åˆ«
    if args.scan:
        print("\nğŸ” æ‰«ææ•°æ®é›†ä¸­çš„ç±»åˆ«...")
        classes = scan_voc_classes(voc_dir)
        
        if classes:
            print(f"\nâœ… æ‰¾åˆ°çš„ç±»åˆ« ({len(classes)} ä¸ª):")
            for i, cls in enumerate(sorted(classes)):
                print(f"  {i}: {cls}")
            
            print(f"\nğŸ’¡ ä½¿ç”¨æ–¹æ³•ç¤ºä¾‹:")
            classes_str = ' '.join(sorted(classes))
            print(f"python utils/voc_to_yolo.py \"{voc_dir}\" --classes {classes_str}")
            print(f"æˆ–è€…ä½¿ç”¨è‡ªåŠ¨æ¨¡å¼:")
            print(f"python utils/voc_to_yolo.py \"{voc_dir}\" --auto")
        else:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•ç±»åˆ«")
        
        return 0
    
    # è‡ªåŠ¨æ¨¡å¼ï¼šè‡ªåŠ¨æ£€æµ‹æ‰€æœ‰ç±»åˆ«
    if args.auto:
        print("\nğŸ” è‡ªåŠ¨æ£€æµ‹ç±»åˆ«...")
        classes = scan_voc_classes(voc_dir)
        
        if not classes:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•ç±»åˆ«")
            return 1
        
        class_names = sorted(list(classes))
        print(f"âœ… è‡ªåŠ¨æ£€æµ‹åˆ° {len(class_names)} ä¸ªç±»åˆ«: {class_names}")
    else:
        # æ£€æŸ¥ç±»åˆ«å‚æ•°
        if not args.classes:
            print("âŒ é”™è¯¯: è¯·æŒ‡å®šç±»åˆ«åç§°")
            print("ğŸ’¡ ä½¿ç”¨ä»¥ä¸‹é€‰é¡¹ä¹‹ä¸€:")
            print("   --scan  æˆ– -s     : æ‰«ææ•°æ®é›†ä¸­çš„æ‰€æœ‰ç±»åˆ«")
            print("   --auto  æˆ– -a     : è‡ªåŠ¨æ£€æµ‹æ‰€æœ‰ç±»åˆ«å¹¶è½¬æ¢")
            print("   --classes æˆ– -c   : æ‰‹åŠ¨æŒ‡å®šç±»åˆ«ï¼Œä¾‹å¦‚: --classes person car bike")
            print(f"\nç¤ºä¾‹:")
            print(f"  python utils/voc_to_yolo.py \"{voc_dir}\" --scan")
            print(f"  python utils/voc_to_yolo.py \"{voc_dir}\" --auto")
            print(f"  python utils/voc_to_yolo.py \"{voc_dir}\" --classes person car bike")
            return 1
        
        class_names = args.classes
    
    print(f"ğŸ·ï¸  æŒ‡å®šç±»åˆ«: {class_names}")
    print(f"ğŸ“Š è®­ç»ƒé›†æ¯”ä¾‹: {args.train_ratio}")
    
    # å¼€å§‹è½¬æ¢
    print(f"\nğŸ”„ å¼€å§‹è½¬æ¢æ•°æ®é›†...")
    success = convert_voc_to_yolo(
        voc_dir=voc_dir,
        output_dir=args.output,
        class_names=class_names,
        train_ratio=args.train_ratio
    )
    
    if success:
        print("\nğŸ‰ è½¬æ¢æˆåŠŸ!")
        print(f"ğŸ’¡ ç°åœ¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¼€å§‹è®­ç»ƒ:")
        print(f"   python scripts/train.py --data {args.output}/dataset.yaml")
        return 0
    else:
        print("\nâŒ è½¬æ¢å¤±è´¥")
        return 1

if __name__ == '__main__':
    exit(main())
