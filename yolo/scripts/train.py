#!/usr/bin/env python3
"""
YOLOv11 è®­ç»ƒè„šæœ¬

åŠŸèƒ½: ä½¿ç”¨YOLOæ¨¡å‹è¿›è¡Œç›®æ ‡æ£€æµ‹è®­ç»ƒ
ä½¿ç”¨æ–¹æ³•: python scripts/train.py --data data/dataset.yaml --model yolo11n.pt --epochs 100

Author: JackZhai
Date: 2025-07-24
"""

import argparse
import os
import sys
import gc
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
ROOT = Path(__file__).resolve().parent.parent
sys.path.append(str(ROOT))

from ultralytics import YOLO
import torch

def parse_args():
    """
    è§£æå‘½ä»¤è¡Œå‚æ•°
    
    Returns:
        argparse.Namespace: åŒ…å«æ‰€æœ‰å‘½ä»¤è¡Œå‚æ•°çš„å‘½åç©ºé—´å¯¹è±¡
    """
    parser = argparse.ArgumentParser(description='YOLOv11 è®­ç»ƒè„šæœ¬')
    
    # æ•°æ®å’Œæ¨¡å‹å‚æ•°
    parser.add_argument('--data', type=str, default='data/dataset.yaml', 
                       help='æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--model', type=str, default='yolo11n.pt', 
                       help='é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„')
    
    # è®­ç»ƒè¶…å‚æ•°
    parser.add_argument('--epochs', type=int, default=100, 
                       help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--imgsz', type=int, default=640, 
                       help='è¾“å…¥å›¾åƒå°ºå¯¸')
    parser.add_argument('--batch-size', type=int, default=4, 
                       help='æ‰¹æ¬¡å¤§å°', dest='batch_size')
    parser.add_argument('--lr0', type=float, default=0.01, 
                       help='åˆå§‹å­¦ä¹ ç‡')
    parser.add_argument('--weight-decay', type=float, default=0.0005, 
                       help='æƒé‡è¡°å‡', dest='weight_decay')
    
    # ç¡¬ä»¶å’Œæ€§èƒ½å‚æ•°
    parser.add_argument('--device', type=str, default='', 
                       help='è®­ç»ƒè®¾å¤‡ (cuda/cpu/mps)')
    parser.add_argument('--workers', type=int, default=0, 
                       help='æ•°æ®åŠ è½½çº¿ç¨‹æ•°')
    
    # è¾“å‡ºå’Œæ¢å¤å‚æ•°
    parser.add_argument('--project', type=str, default='runs/train', 
                       help='ä¿å­˜ç»“æœçš„é¡¹ç›®ç›®å½•')
    parser.add_argument('--name', type=str, default='exp', 
                       help='å®éªŒåç§°')
    parser.add_argument('--resume', action='store_true', 
                       help='æ¢å¤è®­ç»ƒ')
    parser.add_argument('--amp', action='store_true', 
                       help='ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ')
    
    return parser.parse_args()

def check_gpu_info(device):
    """
    æ£€æŸ¥å¹¶æ˜¾ç¤ºGPUä¿¡æ¯ï¼Œæä¾›ç¡¬ä»¶ç›¸å…³å»ºè®®
    
    Args:
        device (str): æŒ‡å®šçš„è®¾å¤‡ç±»å‹
        
    Returns:
        str: å®é™…ä½¿ç”¨çš„è®¾å¤‡ç±»å‹
    """
    device = device or ('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
    
    if torch.cuda.is_available():
        print(f"âš¡ CUDA ç‰ˆæœ¬: {torch.version.cuda}")
        print(f"ğŸ® GPU æ•°é‡: {torch.cuda.device_count()}")
        
        for i in range(torch.cuda.device_count()):
            gpu_name = torch.cuda.get_device_name(i)
            gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
            print(f"   GPU {i}: {gpu_name} ({gpu_memory:.1f}GB)")
            
            # æ ¹æ®æ˜¾å­˜å¤§å°ç»™å‡ºå»ºè®®
            if gpu_memory < 6:
                print(f"   ğŸ’¡ æ˜¾å­˜è¾ƒå°ï¼Œå»ºè®®ä½¿ç”¨è¾ƒå°çš„æ‰¹æ¬¡å¤§å° (batch-size=4)")
            elif gpu_memory < 8:
                print(f"   ğŸ’¡ æ˜¾å­˜ä¸­ç­‰ï¼Œå»ºè®®æ‰¹æ¬¡å¤§å° (batch-size=8)")
            else:
                print(f"   ğŸ’¡ æ˜¾å­˜å……è¶³ï¼Œå¯ä½¿ç”¨è¾ƒå¤§æ‰¹æ¬¡å¤§å° (batch-size=16)")
    else:
        print("âš ï¸  CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ")
    
    return device


def validate_dataset(data_path):
    """
    éªŒè¯æ•°æ®é›†é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    
    Args:
        data_path (str): æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„
        
    Returns:
        bool: æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    """
    if not os.path.exists(data_path):
        print(f"âŒ é”™è¯¯: æ•°æ®é›†é…ç½®æ–‡ä»¶ {data_path} ä¸å­˜åœ¨")
        return False
    return True


def print_training_config(args, device):
    """
    æ‰“å°è®­ç»ƒé…ç½®ä¿¡æ¯
    
    Args:
        args: å‘½ä»¤è¡Œå‚æ•°
        device (str): è®­ç»ƒè®¾å¤‡
    """
    print("\nğŸ”§ è®­ç»ƒé…ç½®:")
    print(f"   ğŸ“‚ æ•°æ®é›†: {args.data}")
    print(f"   ğŸ”„ è®­ç»ƒè½®æ•°: {args.epochs}")
    print(f"   ğŸ“¦ æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    print(f"   ğŸ“ å›¾åƒå°ºå¯¸: {args.imgsz}")
    print(f"   ğŸ“ˆ å­¦ä¹ ç‡: {args.lr0}")
    print(f"   âš–ï¸  æƒé‡è¡°å‡: {args.weight_decay}")
    print(f"   ğŸ–¥ï¸  è®¾å¤‡: {device}")
    print(f"   ğŸ‘· å·¥ä½œçº¿ç¨‹: {args.workers}")
    print(f"   ğŸ“ è¾“å‡ºç›®å½•: {args.project}/{args.name}")
    print(f"   âš¡ æ··åˆç²¾åº¦: {args.amp}")


def clean_memory():
    """æ¸…ç†å†…å­˜å’ŒGPUç¼“å­˜"""
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        print("   ğŸ§¹ GPUå†…å­˜æ¸…ç†å®Œæˆ")


def main():
    """
    ä¸»å‡½æ•°ï¼šæ‰§è¡Œæ¨¡å‹è®­ç»ƒçš„å®Œæ•´æµç¨‹
    
    Returns:
        int: ç¨‹åºé€€å‡ºç  (0: æˆåŠŸ, 1: å¤±è´¥)
    """
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_args()
    
    # æ£€æŸ¥GPUä¿¡æ¯å¹¶ç¡®å®šä½¿ç”¨è®¾å¤‡
    device = check_gpu_info(args.device)
    
    # éªŒè¯æ•°æ®é›†é…ç½®æ–‡ä»¶
    if not validate_dataset(args.data):
        return 1
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.project, exist_ok=True)
    
    try:
        # åˆå§‹åŒ–æ¨¡å‹
        print(f"\nğŸ”„ åŠ è½½æ¨¡å‹: {args.model}")
        model = YOLO(args.model)
        
        # æ˜¾ç¤ºè®­ç»ƒé…ç½®
        print_training_config(args, device)
        
        # é¢„è®­ç»ƒæç¤º
        print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ...")
        print("ğŸ“ æ³¨æ„: é¦–æ¬¡è®­ç»ƒæ—¶æ•°æ®é¢„å¤„ç†å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
        print("ğŸ’¡ ä½¿ç”¨ä¿å®ˆé…ç½®é¿å…è®­ç»ƒä¸­æ–­...")
        print("   - å·¥ä½œçº¿ç¨‹: 0 (é¿å…å¤šè¿›ç¨‹é—®é¢˜)")
        print("   - æ‰¹æ¬¡å¤§å°: 4 (æ›´ç¨³å®š)")
        print("   - å…³é—­å¤æ‚æ•°æ®å¢å¼º")
        
        # æ¸…ç†å†…å­˜
        clean_memory()
        
        # å¼€å§‹è®­ç»ƒ - ä½¿ç”¨ç¨³å®šçš„é…ç½®å‚æ•°
        print("âš¡ å¼€å§‹æ¨¡å‹è®­ç»ƒ...")
        results = model.train(
            data=args.data,
            epochs=args.epochs,
            imgsz=args.imgsz,
            batch=args.batch_size,
            lr0=args.lr0,
            weight_decay=args.weight_decay,
            device=device,
            workers=0,           # å•çº¿ç¨‹æ•°æ®åŠ è½½ï¼Œé¿å…å¤šè¿›ç¨‹é—®é¢˜
            project=args.project,
            name=args.name,
            resume=args.resume,
            amp=args.amp,
            save=True,
            save_period=5,       # æ¯5è½®ä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹
            cache=False,         # å…³é—­ç¼“å­˜ä»¥èŠ‚çœå†…å­˜
            plots=False,         # å…³é—­å›¾è¡¨ç”Ÿæˆä»¥èŠ‚çœæ—¶é—´
            verbose=True,
            patience=20,         # å¢åŠ æ—©åœè€å¿ƒå€¼
            exist_ok=True,
        )
        
        # è®­ç»ƒå®Œæˆä¿¡æ¯
        print("\nğŸ‰ è®­ç»ƒå®Œæˆ!")
        print(f"ğŸ“ æœ€ä½³æ¨¡å‹ä¿å­˜åœ¨: {results.save_dir}/weights/best.pt")
        print(f"ğŸ“ æœ€åæ¨¡å‹ä¿å­˜åœ¨: {results.save_dir}/weights/last.pt")
        print(f"ğŸ“Š è®­ç»ƒç»“æœä¿å­˜åœ¨: {results.save_dir}")
        
    except KeyboardInterrupt:
        print("\nâš ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        return 1
        
    except RuntimeError as e:
        if "out of memory" in str(e).lower():
            print("\nâŒ GPUæ˜¾å­˜ä¸è¶³ï¼")
            print("ğŸ’¡ å»ºè®®:")
            print("   - å‡å°æ‰¹æ¬¡å¤§å°: --batch-size 4")
            print("   - å‡å°å›¾åƒå°ºå¯¸: --imgsz 416")
            print("   - ä½¿ç”¨CPUè®­ç»ƒ: --device cpu")
        else:
            print(f"\nâŒ è¿è¡Œæ—¶é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1
        
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0

if __name__ == '__main__':
    exit(main())
